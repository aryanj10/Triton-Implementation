version: "3.9"

services:
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    entrypoint: >
        python3 -m vllm.entrypoints.openai.api_server
        --model /models/vllm_model/1
        --tokenizer /models/vllm_model/1
        --dtype float16
        --port 8008
        --max-num-seqs 8
    volumes:
      - ./models:/models
    ports:
      - "8008:8008"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              device_ids: ["2"]


  frontend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: fastapi-frontend
    ports:
      - "8081:8081"
    depends_on:
      - vllm
    environment:
      - OPENAI_BASE=http://vllm:8008/v1